% Min: In most of the paper SWING is NUS1.  It's a bit difficult to use the acronym SWING, as it doesn't appear anywhere.  It would be good if you could reference SWING not just in the envelope sections (i.e., intro, conclusion) but also in the meat of the paper.
%In this paper we present our \SWING\ summarization system, and briefly described the two runs we  submitted for the TAC 2011 Guided Summarization task. There are two unique characteristics for the guided summarization task --- categories and aspects.  We formulate our methods to address the acquisition of category-specific information of each topic using the collective knowledge provided in the whole data set. Our initial efforts towards answering aspects make use of named entity information at the topical level. Both automatic and manual evaluation measures validate that our category-specific methods are very effective in producing a guided summary. In future work, we look towards devising more sophisticated features to capture aspect-specific information, as well as examining the integration of aspect-based scores with category-specific scores.
We have shown that using category-specific information (CSI) can significantly improve the performance of topic oriented summaries.  We model CSI into two features: category relevance score (CRS), an intra-category measure; and category KL-divergence (CKLD), an inter-category measure.  Simple to compute and requiring no external knowledge or corpus, the combined use of both CRS and CKLD significantly improved automated ROUGE scores, leading to a basic extractive summarization system that leads the state-of-the-art. 

To probe more deeply, we assessed how to improve CSI features by limiting its calculation to word occurrences that occur within NP chunks.  We also showed that automatically aquired category information (through clustering) still yields improved results, even when the artificially induced categories are noisy.  Finally we performed a micro-analysis of the effect of CSI, studying the changes in sentence selection in the test dataset.  This process showed that the incorporation of CSI changed selection selection significantly.  The analysis also yielded insights about future directions for extractive sentence selection. 

The use of CSI can be incorporated with sophisticated sentence post-processing that is a focus of current summarization research.  As such, we see CSI as a foundational contribution that we urge other summarization platforms to adopt.  To aid this adoption, we have open-sourced our package for the research community to use\footnote{\url{http://removed-for-blind-review/}}.

% We also illustrated that the purity of category labels play a vital role in producing significantly better summaries. We showed that CSI features works better when restricted to NP chunks rather than the whole sentences. We also identified that categories with general aspects are easier to summarize and similar trend follows for CSI. In future work, we look towards devising more sophisticated features to capture aspect-specific information, as well as examining the integration of aspect-based scores with category-specific scores. We also plan to capitalize on the numerical information and attribute more importance to monetary damages, temporal markers and casualty information in certain topics. 


