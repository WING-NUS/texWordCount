% Min: dropped.  Didn't add any useful information.
% Text Summarization is a well-studied area both  Natural Language Processing and Information Retrieval areas.
Studies have been done on many facets of text summarization including multi-document summarization, query focused summarization~\cite{summ:multidoc}, personalized summarization~\cite{summ:personalized}, and temporal summarization~\cite{ICON_2009}. The Guided Summarization task at the Text Analysis Conference (TAC)\footnote{\url{http://www.nist.gov/tac/2011/Summarization/}} provides a forum to disseminate recent results and shared task to focus research efforts in new directions in summarization. In multi-document summarization, a \textit{topic} consists of topically related documents.  In the guided summarization tasks defined by the recent 2011 TAC shared task, each topic is also assigned to one of several broad \textit{categories} such as \emph{Accidents} or \emph{Attacks}. In traditional query-focused summarization, a narrative specific to each topic serves as a hint to the content required in the eventual summary. However in guided summarization, the narrative is replaced with a series of category-specifc templates which contain information elements, or \emph{aspects}.
% Min: give an example. ``For example, XX is an aspect that could be shared by both the accidents and attacks categories.
% JP-20120830
For example, \emph{WHEN} is an aspect that is shared by both the \emph{Accidents} and \emph{Attacks} category.
Aspects are not specific to a topic, but specific rather to the category of topics. A summary for a topic should answer all the aspects of its associated template. Such aspect-oriented summarization can be usefully applied to product opinion summarization, personalization of summaries for users, and improving user experience in question answering scenarios.

Recently, \shortcite{summ:contentmodels} proposed several content models for summarization. Their models find aspects within a topic which are subsequently combined using KL-divergence as a criterion for selecting relevant sentences. \shortcite{CLASSY-TAC2010} augmented their CLASSY system with a query generation component that expands query terms for each aspect of the associated category by performing searches over Google, dictionaries, thesauri and authored world knowledge. \shortcite{JRC-TAC2010} generated guided summaries by framing the problem as an information extraction task. Aspect information extracted from an entity extractor is coupled with a latent semantic analysis model to capture relevant information. They also built lexicons for some category aspects that are not identified by the event extractor.  External knowledge such as Wikipedia is also used by many groups for this task. In \cite{IIIT-TAC2010}, a large set of relevant articles were manually selected from Wikipedia for each category. These articles were used to build domain models, and later to extract important sentences containing events mentioned in the template.

Most of the prior work in aspect-oriented summarization focuses on producing a summary by selecting relevant aspects in \emph{a single topic}. However, aspects are shared over multiple topics in a category; as such, topic-oriented models do not exploit the shared knowledge among categorically related topics. We hypothesize that category-specific information does encode a useful signal that can improve the quality of guided summaries. To this effect, we propose and develop a robust sentence-extractive summarizer adopting the standard, supervised machine learning framework: we extract features from the input documents, utilize the features to rank the importance of input sentences through a regression model, and finally apply the model on new, unseen test documents.
%  The set of features employed include simple heuristics (length of sentence, positional information of sentence in the article), and frequency measures (document frequency).
%While these features help to determine the generic importance of individual sentences,
The fundamental innovation that our summarizer makes over the previous state-of-the-art is that it makes use of the information derived from the category of topic to calculate the category-specific importance (CSI) of each sentence. We capture CSI through two novel features -- \textit{category relevance score} and \textit{category Kullback-Liebler divergence} -- that are explained in later sections of the paper.

Our approach is different from the previous work~\cite{CLASSY-TAC2010,JRC-TAC2010} that manually compiled lexicons for each category aspect. Words in the pre-compiled lexicons are treated equally important for a category in these prior work, whereas our method automatically discerns between the different saliency of words across a category. Such automated methods address the problem of low recall that hampers the performance of manually-compiled lexica. When compared with the state-of-the-art summarizers submitted to TAC 2011, our system significantly outperforms all other systems.
